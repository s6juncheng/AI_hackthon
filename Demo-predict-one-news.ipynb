{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to parse url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://fox13now.com/2013/12/30/new-year-new-laws-obamacare-pot-guns-and-drones/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text_title(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    text = article.text\n",
    "    title = article.title\n",
    "    return title, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title, text = get_text_title(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def rm_punctuation(tokenized):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation)) \n",
    "    new_tokenized = []\n",
    "    for token in tokenized:\n",
    "        new_token = regex.sub(u'', token)\n",
    "        if not new_token == u'':\n",
    "            new_tokenized.append(new_token)\n",
    "    return new_tokenized\n",
    "\n",
    "def rm_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if not word in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stemming(words):\n",
    "    snowball = SnowballStemmer('english')\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(snowball.stem(word))\n",
    "    return new_words\n",
    "\n",
    "def clean_text(text):\n",
    "    # tokenize\n",
    "    tokenized = word_tokenize(text)\n",
    "    punc_rmd = rm_punctuation(tokenized)\n",
    "    stw_rmd = rm_stopwords(punc_rmd)\n",
    "    stmd = stemming(stw_rmd)\n",
    "    new_text = \" \".join(stmd)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new year new law obamacar pot gun drone'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = pickle.load(open(\"./data/tokenizer.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2indx(text, trained_tokenizer, max_len=2000):\n",
    "    if isinstance(text, str):\n",
    "        # single string text\n",
    "        text = [text]\n",
    "    tokenizer = trained_tokenizer\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    data = pad_sequences(sequences, maxlen=max_len)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 18190,   691,     6]], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inded = word2indx(text, tokenizer)\n",
    "inded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"./data/models/CNN_LSTM2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_from_index(model, index):\n",
    "    prediction = model.predict(index).flatten()\n",
    "    prob_true = prediction[0] * 100\n",
    "    prob_false = prediction[1] * 100\n",
    "    if prob_true >= 0.7:\n",
    "        print(\"Likely a true news! (%0.3f percent confident)\" % prob_true)\n",
    "    elif prob_true >= 0.5:\n",
    "        print(\"Maybe a true news, not every sure (%0.3f percent confident)\")\n",
    "    elif prob_true < 0.5 & prob_true > 0.3:\n",
    "        print(\"This is mabye a fake news (%0.3f percent confident)\" % prob_false)\n",
    "    elif prob_false >= 0.7:\n",
    "        print(\"Attention! Likely a fake news! (%0.3f percent confident)\"% prob_false)\n",
    "    else:\n",
    "        print(\"We are %0.3f percent confident that this is a true news\" % prob_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likely a true news! (99.831 percent confident)\n"
     ]
    }
   ],
   "source": [
    "predict_from_index(model, inded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_news(model, url, trained_tokenizer, max_len=2000):\n",
    "    title, text = get_text_title(url)\n",
    "    cleaned = clean_text(text)\n",
    "    index = word2indx(cleaned, trained_tokenizer, max_len)\n",
    "    predict_from_index(model, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is likely to be a true news (98.860 percent confident)\n"
     ]
    }
   ],
   "source": [
    "predict_news(model, url, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from src.prediction import predict_news, get_text_title\n",
    "from keras.models import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./data/models/CNN_LSTM2\")\n",
    "tokenizer = pickle.load(open(\"./data/tokenizer.pkl\", 'rb'))                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Image copyright Defensoría del Pueblo de Colombia Image caption The freed journalists (second and third from left) with a delegation of the Colombian Ombudsman\\'s Office\\n\\nTwo Dutch journalists abducted last weekend by rebels in Colombia have been released after a day of conflicting reports about their fate.\\n\\nDerk Bolt and Eugenio Follender were handed over to a delegation from the Colombian Ombudsman\\'s Office, the agency confirmed in a tweet.\\n\\nNational Liberation Army (ELN) rebels said they had freed them on Friday but later retracted the announcement.\\n\\nFears were raised for peace talks between the rebels and the government.\\n\\nImage copyright Defensoría del Pueblo de Colombia Image caption The ELN fighters were heavily armed\\n\\nHowever, the Dutch pair were finally handed over in a rural area of the Catatumbo region, near the border with Venezuela.\\n\\nDutch Foreign Minister Bert Koenders welcomed the release as \"very good news\" and thanked the Colombian authorities for having worked hard to free the men.\\n\\nPhotos released by the Ombudsman\\'s Office show the Dutchmen flanked by armed and masked ELN fighters before being transferred to its delegation.\\n\\nThe Colombian Ombudsman\\'s Office, or Defensoría del Pueblo de Colombia, is a national government agency which oversees the protection of civil and human rights.\\n\\n\\'It was quite heavy\\'\\n\\nTelevision journalist Bolt, 62, and cameraman Follender, 58, had been on an assignment to search for the mother of a Colombian child adopted in the Netherlands when they were taken.\\n\\nIn an interview picked up by fellow Dutch journalist Edwin Koopman, Bolt told Colombian broadcaster Caracol Radio the rebels had given him a \"very long\" document containing points about the peace talks.\\n\\nImage copyright Reuters Image caption Protests have been held across Colombia this week to demand the release of the two Dutch journalists\\n\\nHe and Follender, he said, were both well apart from some minor cuts from bushes.\\n\\nThey had thought they were being robbed when they were kidnapped, he said. They were kept hidden in houses but one day they were made to walk for 14 hours to evade the army.\\n\\nBut the rebels had been respectful and never threatened to kill them, he told the radio.\\n\\n\"It was rather heavy,\" he said, \"but the people accompanying us were quite nice.\"\\n\\n\"While our families at home feared for us, we were sitting drinking coffee with the guerrillas.\"\\n\\n\\'Pleased and relieved\\'\\n\\nDutch broadcaster Kro-Ncrv TV, whose Spoorloos programme the journalists were working for, said it was \"pleased and relieved\" that Bolt and Follender were free.\\n\\n\"We are grateful to everyone who has worked to release Derk and Eugenio,\" it added in comments quoted by AFP news agency.\\n\\n\"In particular, we thank the foreign ministry. They have really done everything in The Hague and in Colombia in order to bring this about.\"\\n\\nLast year the ELN kidnapped a Spanish journalist and several Colombians in the same area. All were later released.\\n\\nThe ELN is the second largest left-wing guerrilla group in Colombia, behind the Farc.\\n\\nThe Farc signed a peace deal with the government last November and are preparing to enter civilian life but the ELN only started peace talks in February this year.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.bbc.com/news/world-latin-america-40391221\"\n",
    "title, text = get_text_title(url)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention! Likely a fake news! (98.951 percent confident)\n"
     ]
    }
   ],
   "source": [
    "predict_news(model, url, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake news websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "247NewsMedia.com\n",
    "http://www.rappler.com/nation/173832-cbcp-list-websites-fake-news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://abcnews.com.co/specifics-tugboats-maritime-law/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_text(model, text, trained_tokenizer, max_len=2000):\n",
    "    cleaned = clean_text(text)\n",
    "    index = word2indx(cleaned, trained_tokenizer, max_len)\n",
    "    prediction = model.predict(index).flatten()\n",
    "    prob_true = float(prediction[0] * 100)\n",
    "    return prob_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'project/news'\n",
      "/data/nasif12/home_if12/chengju/project/news\n"
     ]
    }
   ],
   "source": [
    "cd project/news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.prediction import clean_text, word2indx, predict_from_index \n",
    "\n",
    "fkn = pd.read_pickle(\"./data/fkn.gzip\")\n",
    "texts = fkn[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = texts.apply(lambda x: predict_text(model, \" \".join(x), tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fkn1 = fkn[y_pred > 80]\n",
    "texts = fkn1[\"text\"]\n",
    "texts = texts.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "wordcloud2 = WordCloud(\n",
    "                          stopwords=STOPWORDS,\n",
    "                          background_color='white',\n",
    "                          width=1200,\n",
    "                          height=1000\n",
    "                         ).generate(\" \".join(texts))\n",
    "\n",
    "\n",
    "plt.imshow(wordcloud2)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig(\"LSTMtrue.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
